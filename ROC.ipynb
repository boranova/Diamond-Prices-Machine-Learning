{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to CSV and read in CSV\n",
    "csv_path = Path('Resources/diamonds.csv')\n",
    "df=pd.read_csv(csv_path)\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "cut_num = {\n",
    "    'Ideal': 1,\n",
    "    'Premium': 2,\n",
    "    'Good': 3,\n",
    "    'Very Good': 4,\n",
    "    'Fair': 5,\n",
    "}\n",
    "df[\"cut_num\"] = df[\"cut\"].apply(lambda x: cut_num[x])\n",
    "df['p_bin'] = pd.qcut(df['price'], q=10, precision=0)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['p_bin'])\n",
    "df['p_bin_num'] = le.transform(df['p_bin'])\n",
    "df.drop(['cut','price','p_bin'], axis=1, inplace=True)\n",
    "df_enc = pd.get_dummies(df, columns=['color','clarity'])\n",
    "\n",
    "X = df_enc.drop(columns=['p_bin_num'])\n",
    "y = df_enc.p_bin_num\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(X_train_scaled, y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Random Forrest Classifier\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=500, random_state=7)\n",
    "model2 = model2.fit(X_train_scaled, y_train)\n",
    "predictions2 = model2.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "# Gradient Boost\n",
    "\n",
    "model3 = GradientBoostingClassifier(    n_estimators=500,\n",
    "    learning_rate=0.5,\n",
    "    max_features=5,\n",
    "    max_depth=3,\n",
    "    random_state=7)\n",
    "\n",
    "model3 = model3.fit(X_train_scaled, y_train)\n",
    "predictions3 = model3.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aac71ac29448>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate the ROC curve and AUC for the testing set for Tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfpr_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mauc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mauc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nnenv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nnenv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[1;32m    775\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 776\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/nnenv/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    537\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    538\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "# Calculate the ROC curve and AUC for the testing set for Tree\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, predictions)\n",
    "\n",
    "auc_test = auc(fpr_test, tpr_test)\n",
    "auc_test = round(auc_test, 4)\n",
    "\n",
    "\n",
    "fpr_test_rf, tpr_test_rf, thresholds_test_rf = roc_curve(y_test, predictions2)\n",
    "\n",
    "auc_test_rf = auc(fpr_test_rf, tpr_test_rf)\n",
    "auc_test_rf = round(auc_test_rf, 4)\n",
    "\n",
    "\n",
    "\n",
    "fpr_test_gb, tpr_test_gb, thresholds_test_gb = roc_curve(y_test, predictions3)\n",
    "\n",
    "auc_test_gb = auc(fpr_test_gb, tpr_test_gb)\n",
    "auc_test_gb = round(auc_test_gb, 4)\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame with the fpr and tpr results\n",
    "roc_df_tree = pd.DataFrame({\"FPR Train\": fpr_train, \"TPR Train\": tpr_train,})\n",
    "\n",
    "roc_df_rf = pd.DataFrame({\"FPR Test\": fpr_test_rf, \"TPR Test\": tpr_test,})\n",
    "roc_df_gb = pd.DataFrame({\"FPR Test\": fpr_test_gb, \"TPR Test\": tpr_test,})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the ROC Curves\n",
    "roc_df_tree.plot(\n",
    "    x=\"FPR Train\",\n",
    "    y=\"TPR Train\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Train ROC Curve (AUC={auc_test})\",\n",
    ")\n",
    "\n",
    "roc_df_rf.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"red\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test_rf})\",\n",
    ")\n",
    "\n",
    "roc_df_gb.plot(\n",
    "    x=\"FPR Test\",\n",
    "    y=\"TPR Test\",\n",
    "    color=\"red\",\n",
    "    style=\"--\",\n",
    "    xlim=([-0.05, 1.05]),\n",
    "    title=f\"Test ROC Curve (AUC={auc_test_gb})\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
